{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input for DeCiFer\n",
    "\n",
    "This notebook provides an exemplary script for generating the input for DeCiFer from multiple bulk tumour samples and matched normal sample when using:\n",
    "- HATCHet for inferring allele-specific copy numbers\n",
    "- Varscan for inverring somatic single-nucleotide variants (SNVs)\n",
    "- BCFtools for counting sequencing reads for all SNVs across all tumour samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Required inputs\n",
    "\n",
    "There are three required inputs that should be provided in the related variables below.\n",
    "\n",
    "1. **`CNAs`**: `best.seg.ucn` file with HATCHet's inferred allele-specific copy numbers.\n",
    "2. **`SNVs`**: Varscan output TSV file with somatic SNVs (mandatory fields include `chrom`, `position`, `ref`, and `var`) called for every sample independently. \n",
    "3. **`MPIs`**: BCFtools files of read counts generated for every tumour sample independently and for all genomic positions of all SNVs present across all `${SNVs}`. Specifically, each file `${SAMPLE}.mpileup.tsv` should be generated with a command equivalent to the follow for every sample `${SAM}`, with reference genome `${REF}`, SNV files `${SNV1} ... ${SNVN}` from 2. above, and when `chrom` and `position` are the first two columns of the files in 2. (otherwise change `-f1,2` to match):\n",
    "```shell\n",
    "bcftools mpileup ${SAM} -f ${REF} -T <(cat ${SNV1} ... ${SNVN} | cut -f1,2 | sort -k2,2 -k1,1 | uniq | grep -v position) -a INFO/AD -Ou | bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\t%AD\\n' > ${SAMPLE}.mpileup.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please specify the required inputs in the three related variables with the suggested format\n",
    "\n",
    "CNAs = '/path/to/best.seg.ucn'\n",
    "SNVs = {\n",
    "    'SAMPLE1' : '/path/to/SAMPLE1.varscan.tsv',\n",
    "    'SAMPLE2' : '/path/to/SAMPLE2.varscan.tsv',\n",
    "}\n",
    "MPIs = {\n",
    "    'SAMPLE1' : '/path/to/SAMPLE1.mpileup.tsv',\n",
    "    'SAMPLE2' : '/path/to/SAMPLE2.mpileup.tsv',\n",
    "}\n",
    "\n",
    "## Also, please specify the name or full path of the two generated input files for DeCiFer\n",
    "\n",
    "INPUT_SNVs = 'decifer.input.tsv'\n",
    "INPUT_PURITY = 'decifer.purity.tsv'\n",
    "\n",
    "## Finally, the following parameters are used for variant filtering\n",
    "\n",
    "PVALUE = 1e-03 # Maximum threshold for Varscan pvalue score, choose 1 if you want to disable it.\n",
    "MINREADS = 30 # Minimum total number of reads per SNV across all samples\n",
    "MAXREADS = 10000 # Maximum total number of reads per SNV across all samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Execute the script for creating DeCiFer's input\n",
    "\n",
    "After succesfully setting up the required inputs, the following steps can be executed directly through this python notebook (or as a python script) to create DeCiFer input. When using this jupyter notebook, simply run all the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## SNVs data and read counts are properly combined and formatted\n",
    "\n",
    "snv_df = {}\n",
    "for sam, f in SNVs.items():\n",
    "    snv_df[sam] = pd.read_csv(f, sep='\\t')\n",
    "    snv_df[sam] = snv_df[sam][snv_df[sam]['somatic_p_value'] < PVALUE]\n",
    "    snv_df[sam]['snv_id'] = snv_df[sam].apply(lambda line: \".\".join(map(str, [line['chrom'], line['position'], line['ref'], line['var']])), axis=1)\n",
    "mpi = {}\n",
    "form = (lambda p : ((p[0], int(p[1])), Counter(dict(filter(lambda v : '*' not in v[0], zip(p[2].split(','), map(int, p[3].split(','))))))))\n",
    "for sam, f in MPIs.items():\n",
    "    mpi[sam] = defaultdict(lambda : Counter({'A' : 0, 'C' : 0, 'G' : 0, 'T' : 0}))\n",
    "    with open(f, 'r') as i:\n",
    "        for l in i:\n",
    "            g, u = form(l.strip().split())\n",
    "            mpi[sam][g].update(u)\n",
    "        mpi[sam] = dict(mpi[sam])\n",
    "refvar = defaultdict(lambda : (Counter({'A' : 0, 'C' : 0, 'G' : 0, 'T' : 0}), Counter({'A' : 0, 'C' : 0, 'G' : 0, 'T' : 0})))\n",
    "for sam in snv_df:\n",
    "    for i, r in snv_df[sam].iterrows():\n",
    "        g = (str(r['chrom']), r['position'])\n",
    "        refvar[g][0].update(Counter({r['ref'] : mpi[sam][g][r['ref']]}))\n",
    "        refvar[g][1].update(Counter({r['var'] : mpi[sam][g][r['var']]}))\n",
    "refvar = {g : refvar[g] for g in refvar if sum(refvar[g][0].values()) > 0 and sum(refvar[g][1].values()) > 0 and MINREADS <= (sum(refvar[g][0].values()) + sum(refvar[g][1].values())) <= MAXREADS}\n",
    "argmax = (lambda D : max(D.keys(), key=(lambda x : D[x])))\n",
    "refvar = {g : tuple(map(argmax, refvar[g])) for g in refvar}\n",
    "assert all(refvar[g][0] != refvar[g][1] for g in refvar)\n",
    "gid = (lambda g : '.'.join(map(str, [g[0], g[1], refvar[g][0], refvar[g][1]])))\n",
    "form = (lambda s, g : {'snv_id' : gid(g), 'Sample' : s, 'chrom' : g[0], 'position' : g[1], 'tumor_reads1' : mpi[s][g][refvar[g][0]], 'tumor_reads2' : mpi[s][g][refvar[g][1]]})\n",
    "default = (lambda s, g : {'snv_id' : gid(g), 'Sample' : s, 'chrom' : g[0], 'position' : g[1], 'tumor_reads1' : 1, 'tumor_reads2' : 0})\n",
    "snv_df = pd.DataFrame([form(s, g) if g in mpi[s] else default(s, g) for s in mpi for g in refvar])\n",
    "selected_ids = snv_df['snv_id'].unique()\n",
    "print('Number of selected SNVs: {}'.format(len(selected_ids)))\n",
    "sample_index = {v:i for i, v in enumerate(snv_df['Sample'].unique())}\n",
    "character_index = {v:i for i, v in enumerate(selected_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Read CNAs data and generate purity input\n",
    "\n",
    "cna_df = pd.read_csv(CNAs, sep = '\\t')\n",
    "cna_df['purity'] = 1.0 - cna_df['u_normal']\n",
    "purities = dict({(r['SAMPLE'], r['purity']) for i, r in cna_df.iterrows()})\n",
    "with open(INPUT_PURITY, 'w') as o:\n",
    "    for s in purities:\n",
    "        o.write(\"{}\\t{}\\n\".format(sample_index[s], purities[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Combine SNVs and CNAs data\n",
    "\n",
    "discarded = 0\n",
    "input_data = []\n",
    "for i, snv in enumerate(selected_ids):\n",
    "    highcn = False\n",
    "    buff = []\n",
    "    char_idx = character_index[snv]\n",
    "    char_label = snv\n",
    "    if i % 500 == 0: print(\"{} {}\".format(i, len(character_index)))\n",
    "    for sample in snv_df['Sample'].unique():\n",
    "        sample_idx = sample_index[sample]\n",
    "        \n",
    "        snv_line = snv_df[(snv_df['snv_id'] == snv) & (snv_df['Sample'] == sample)].iloc[0]\n",
    "        try:\n",
    "            chrom = int(snv_line['chrom'])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        pos = int(snv_line['position'])\n",
    "        ref = snv_line['tumor_reads1']\n",
    "        var = snv_line['tumor_reads2']         \n",
    "        intervals = cna_df[(cna_df['#CHR'] == chrom) & (cna_df['START'] <= pos) & (cna_df['END'] > pos) & (cna_df['SAMPLE'] == sample)]\n",
    "        if len(intervals) == 0: \n",
    "            discarded += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            cn_dict = {}\n",
    "            for idx in ['normal', 'clone1', 'clone2', 'clone3', 'clone4', 'clone5', 'clone6', 'clone7', 'clone8', 'clone9', 'clone10']:\n",
    "            \n",
    "                try:\n",
    "                    cn = intervals.iloc[0]['cn_{}'.format(idx)]\n",
    "                    mu = intervals.iloc[0]['u_{}'.format(idx)]\n",
    "                except: \n",
    "                    continue\n",
    "                try:\n",
    "                    cn_dict[cn] += mu\n",
    "                except:\n",
    "                    cn_dict[cn] = mu\n",
    "            \n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "        line = [sample_idx, sample, char_idx, char_label, ref, var]\n",
    "        \n",
    "        states6 = set()\n",
    "        for cn in sorted(cn_dict):\n",
    "            c1a = cn.split('|')[0]\n",
    "            c1b = cn.split('|')[1]\n",
    "            mu1 = cn_dict[cn]\n",
    "            line += [c1a, c1b, mu1]\n",
    "            highcn = highcn or (int(c1a) + int(c1b)) > 6\n",
    "            if (int(c1a) + int(c1b)) == 6:\n",
    "                states6.add((c1a, c1b))\n",
    "        highcn = highcn or len(states6) > 1\n",
    "        buff.append(line)\n",
    "    \n",
    "    if not highcn:\n",
    "        input_data.extend(buff)\n",
    "    else:\n",
    "        discarded += 1\n",
    "print('Discarded {}'.format(discarded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Generate the SNV input for DeCiFer with CNAs\n",
    "\n",
    "with open(INPUT_SNVs, 'w') as out:\n",
    "    out.write('{} #characters\\n'.format(len(selected_ids)))\n",
    "    out.write('{} #samples\\n'.format(len(purities)))\n",
    "    out.write(\"#sample_index\tsample_label\tcharacter_index\tcharacter_label\tref\tvar\\n\")\n",
    "    for line in input_data:\n",
    "        out.write(\"\\t\".join(map(str, line))+\"\\n\")       "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
